\newcount\Comments  
\Comments=1   
\documentclass[a4paper,12pt, english]{article}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{babel}
%\usepackage{amsmath}

\usepackage{color}

\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{purple}{rgb}{1,0,1}
%\usepackage{subcaption}

\newcommand{\kibitz}[2]{\ifnum\Comments=1\textcolor{#1}{#2}\fi}
% add yourself here:
\newcommand{\ls}[1]{\kibitz{red}      {[Larisa: #1]}}
\newcommand{\cg}[1]  {\kibitz{purple}   {[Crina: #1]}}
\newcommand{\ns}[1]{\kibitz{cyan}     {[Noureddin: #1]}}



\usepackage{listings}
\usepackage{url}
%\usepackage{graphicx}

\usepackage{verbatim}

%\usepackage{caption}
%\usepackage{enumitem}

%\onehalfspacing

\begin{document}

\title{A List of Suggestions/Notes/Ideas}
%\date{Mar 2014}
%\author{By: Noureddin Sadawi}
%\maketitle

\large
\section{By Noureddin \date{\today}}
\begin{enumerate}
	\item I have split the dataset from Dundee into 4565 datasets using the column TID (Target ID)
	\item Some datasets are too small ($<$ 10 instances) and some have thousands of instances!
	\item Some stats:
	\begin{enumerate}
	\item No of DS with $>=$ 2000 instances = 74
	\item No of DS with $>=$ 1500 instances = 126
	\item No of DS with $>=$ 1000 instances = 234
	\item No of DS with $>=$ 500 instances = 506
	\end{enumerate}    
	
	\item We have a large list of metrics from WEKA. However, not all are suitable for QSAR studies
	\item There are some domain specific metrics (specific for QSAR) and they're not in WEKA
	\item Some of these domain specific metrics include:  pROC, BEDROC (for ROC curve, they focus on what they denote \emph{early recognition problem}) and RIE
	\item Another metric is called SLR from this paper\footnote{\url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2722655/?tool=pmcentrez&report=abstract}}
	\item Matthew's Correlation Coefficient is also popular\footnote{\url{http://journal.chemistrycentral.com/content/2/1/3}}. It exists in WEKA
	\item There is a paper about \emph{Evaluating Virtual Screening Methods}\footnote{\url{http://www.ncbi.nlm.nih.gov/pubmed/17288412}}. It looks VERY interesting. Maybe I will read it after I come back. Please go through it if you have time!
	
	\item Some Metrics from\footnote{\url{http://www.ncbi.nlm.nih.gov/pubmed/17288412}}:
	\begin{enumerate}
	\item the area under the receiver operating characteristic curve (ROC)
	\item the area under the accumulation curve (AUAC)
	\item the average rank of actives
	\item the enrichment factor (EF)
	\item the robust initial enhancement (RIE)
	\item Boltzmann-enhanced discrimination of receiver operating characteristic (BEDROC)
	\end{enumerate}
	\item \ns{Interesting Presentation} here\footnote{\url{https://www.ebi.ac.uk/training/sites/ebi.ac.uk.training/files/materials/2013/131209DrugDiscovery/1_-_val_gillet_-_ligand-based_and_structure-based_virtual_screening.pdf}}, NS $--->$ MUST go through it to develop better understanding of Virtual Screening/QSAR
	
	\item \ns{Structural Variability of Datasets.} This was suggested by Ross during online meeting on Fri 9 May 2014. He mentioned using Manhattan distance (Crina mentioned Hamming distance)
\end{enumerate}    

\section{By Larisa}
\begin{enumerate}
	\item We have analysed available descriptors from various sources (bottom-up approach), and there are too many of them. We now will try top-down approach. We will consider several datasets, from Dundee and publicly available ones, e.g. from ChEMBL \ns{I think people from Dundee always use ChEMBL} and also several QSAR studies. We will try to annotate them with some descriptors that would convey what is important to record about those datasets and QSAR- specific studies. We then will come up with a set of descriptors that are suited for our task. We will check if what existing resources have the required descriptors, and if necessary we will define new ones (see the next point).
	\item Crina suggested that we can develop new descriptors/ measures that fit better to support our task.
	\item We will target to come up with \textasciitilde50 descriptors and we will evaluate them with experts through questionary and select  ~ 20 the most popular descriptors.
	\item We will also put our questionary to a public domain and give an opportunity to everyone to comment on descriptors. Such an approach would ensure that we identify a set of useful descriptors \ns{I emailed Egon Willighagen\footnote{\url{http://chem-bla-ics.blogspot.co.uk/}} but he has not responded yet}.
\end{enumerate}  


\section{Crina}
My two suggestions during the meeting where:
\begin{itemize}
\item Find the characteristics of the data set (something which defines very well our data and makes the difference between our data and other data sets). For instance, if we say 10 features, this will not make a difference. But if we say 10 features, first 3 are real values, 4 and 5 are binary and 6-10 are real values between 0-1, this will be more specific.
\item define the problem output (or scope): in our case will be binary classification and not regression?\ns{they usually use both but at the end they use a threshold to decide whether the real value resulting from regression indicates compound is active or inactive - and this makes it binary classification}
\item define how we are going to achieve this scope: this may involve more criteria in which case we will need to look at the performance of the methods we apply from various angles
\item define a set of machine learning methods suitable for this scope \ns{popular ones are Naive Bayes and Random Forests, I need to investigate further}
\item define a set of measures or metrics which evaluate these machine learning methods for this scope. Some of the metrics may be standard, but we might need some other aspects and for this we will have to define ourself some measures
\end{itemize}

\cg{Noureddin, put together what you have so far and what you find in the literature strictly for this type of problem  and I can also look after that and complement with what I know.}
		
\end{document}
