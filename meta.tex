\documentclass[a4paper,12pt, english]{article}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\usepackage{babel}
%\usepackage{amsmath}

\usepackage{color}

%\usepackage{subcaption}

\usepackage{listings}
\usepackage{url}
%\usepackage{graphicx}

\usepackage{verbatim}

%\usepackage{caption}
%\usepackage{enumitem}

%\onehalfspacing

\begin{document}

\title{A List of Suggested Dataset Descriptors}
\date{Mar 2014}
\author{By: Noureddin Sadawi}
\maketitle

\large
\section{By Noureddin}
\begin{enumerate}
\item \textbf{Number of Attributes} The number of attributes in the dataset
\item \textbf{Number of Instances}  The number of instances in the dataset
\item \textbf{ClassificationOrRegression}  Whether it's a classification or regression dataset/problem
\item \textbf{Percentage of Nominal Attributes} (Number of Nominal attributes/Number of Attributes) * 100
\item \textbf{Percentage of Binary Attributes} (Number of Binary attributes/Number of Attributes) * 100
\item \textbf{Percentage of Numeric Attributes} (Number of Numeric attributes/Number of Attributes) * 100      


\item \textbf{Has Missing Values} Whether the dataset has missing values (yes $|$ No)
\item \textbf{Percentage of Present Values} (Number of non-missing values/Total Number of values) * 100 
\item \textbf{Percentage of Missing Values} (Number of missing values/Total Number of values) * 100 
\end{enumerate}    

\section{From DMOP}
\begin{enumerate}
		\item \textbf{AverageAbsoluteFeatureCorrelation:} METAL characteristic: Average absolute correlation between continuous features.
		\item \textbf{AverageCategoricalFeaturePairsMutualInformation:}  METAL characteristic: Average mutual information between pairs of categorical features. 
		\item \textbf{AverageFeatureEntropy:} METAL characteristic: Average feature Entropy
		\item \textbf{BetweenGroupsSumSquaresCrossProducts:} METAL characteristic: A matrix containing the difference between the matrix of total and the matrix of within-groups sums of squares and cross products.
		\item \textbf{EigenValuesLinearDiscriminantFunctions:} METAL characteristic: A vector of eigen values of linear discriminant functions.
		\item \textbf{NoiseSignalRatio:}  METAL characteristic: Noise signal ratio
		\item \textbf{NumberOfCategoricalFeatures:}
		\item \textbf{NumberOfContinuousFeatures:}
		\item \textbf{NumberOfFeatures:}
		\item \textbf{NumberOfHOutliers:} METAL characteristic: Number of continuous features with outliers.
		\item \textbf{NumberOfInstances:}
		\item \textbf{NumberOfInstancesPerFeature:} From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006. 
		\item \textbf{ProportionOfCategoricalFeatures:}
		\item \textbf{ProportionOfHOutliers:} METAL characteristic: Proportion of continuous features with outliers.
		\item \textbf{TotalSumSquaresCrossProducts:} METAL characteristic: Matrix of total sums of squares and cross products of features.
		\item \textbf{WithinGroupsSumSquaresCrossProducts:} METAL characteristic: matrix of within-groups sums of squares and cross products of features. 
		\item \textbf{AverageSVMFeatureWeight:}
\end{enumerate}  
\subsection{CategoricalLabeledDataSetCharacteristic}

				\begin{enumerate}
				\item \underline{AverageMutualInformation:} METAL characteristic: Average mutual information 
				\item \underline{AverageReliefFeatureWeight:}
				\item \underline{CanonicalCorrelationBestLinearCombination:} METAL characteristic: Canonical correlation of the best linear combination of features to distinguish between classes.
				\item \underline{ClassAbsoluteFrequencies:} METAL characteristic: Absolute class frequencies. Stored in a vector indexed by each class value.
				\item \underline{ClassCovarianceMatrices:} METAL characteristic: Class covariance matrices. Stored in a vector indexed by class and each containing a matrix of (features x features)
				\item \underline{ClassEntropy:}  METAL characteristic: Class entropy.
				\item \underline{ClassRelativeFrequencies:} METAL characteristic: Relative class frequencies. Stored in a vector indexed by each class value.
				\item \underline{ErrorRateOf1NNClassifier:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{ErrorRateOfLinearClassifierLP:} From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{FeatureMutualInformationPerClass:} METAL characteristic: For each categorical feature, the mutual information between the feature and the class. It is stored in a vector indexed by each categorical feature.
				\item \underline{FeatureValueFrequenciesPerClass:} METAL characteristic: For each k value of each j categorical feature and each i class, the proportion of cases that have the k value in the j feature and belong to the i class. It is stored in a vector indexed by each categorical feature and containing a flat contingency tables that combine the values of the categorical feature with the class values. 
				\item \underline{MaximumFeatureEfficiency:} From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{MaximumFishersDiscriminantRatio:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{MinimumSumOfErrorDistanceByLP:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{NonLinearityOf1NNClassifier:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{NonLinearityOfLinearClassifierLP:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{NumberOfClasses:}
				\item \underline{ProportionOfBoundaryPoints:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{ProportionPointsWithRetainedAdherence:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{RatioOfAverageIntraInterDistances:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\item \underline{VolumeOfOverlapRegion:}  From Mitra Basu and Tin Kam Ho. Data Complexity in Pattern Recognition. Springer, 2006.
				\end{enumerate}	  		
		
\end{document}
